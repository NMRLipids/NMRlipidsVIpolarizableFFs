{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation description file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOI=\"10.5281/zenodo.3557459\"\n",
    "def_file  = \"/home/osollila/NMRlipids/MATCH/scripts/orderParm_defs/order_parameter_definitions_MODEL_CHARMM36_DOPE.def\"\n",
    "\n",
    "user_information = \"\"\"\n",
    "DOPE test\n",
    "#NMRLIPIDS BEGIN\n",
    "\n",
    "@SIM\n",
    "@SOFTWARE=gromacs\n",
    "@FF=CHARMM36\n",
    "@FF_SOURCE=CHARMM-GUI\n",
    "@FF_DATE=??\n",
    "@TRJ=dope.trr\n",
    "@TPR=dope.tpr\n",
    "\n",
    "#NMRLIPIDS END\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Working directory\n",
    "dir_wrk  = \"/media/osollila/DATADRIVE1/temp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with files and directories\n",
    "import os\n",
    "\n",
    "#For quering webs\n",
    "import urllib.request\n",
    "from urllib.error import URLError,HTTPError\n",
    "\n",
    "# From time monitoring\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Python program to find SHA256 hash string of a file\n",
    "import hashlib\n",
    "\n",
    "# For dealing with excel and cvs \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "#To make real independent copies of lists\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/osollila/DATADRIVE1/temp3\n",
      "/home/osollila/NMRlipids/MATCH/scripts/orderParm_defs/order_parameter_definitions_MODEL_CHARMM36_POPE.def\n"
     ]
    }
   ],
   "source": [
    "dir_wrk = os.path.normpath(dir_wrk)\n",
    "print(dir_wrk)\n",
    "def_file = os.path.normpath(def_file)\n",
    "print(def_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the DOI link is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doi.org/10.5281/zenodo.3557459\n",
      "Status of the DOI link: OK\n"
     ]
    }
   ],
   "source": [
    "DOI_url = 'https://doi.org/' + DOI\n",
    "print(DOI_url)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(DOI_url)\n",
    "    print(\"Status of the DOI link: {0}\".format(response.msg))\n",
    "except HTTPError as e:\n",
    "    print(DOI_url)\n",
    "    print('The server couldn\\'t fulfill the request.')\n",
    "    print('Error code: ', e.code)\n",
    "    user_information = \"\"\n",
    "    print('The code will not proceed, please fix DOI')\n",
    "except URLError as e:\n",
    "    print(DOI_url)\n",
    "    print('We failed to reach a server.')\n",
    "    print('Reason: ', e.reason)\n",
    "    user_information = \"\"\n",
    "    print('The code will not proceed, please fix DOI')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[{'ID': 0, 'SOFTWARE': 'gromacs', 'FF': 'CHARMM36', 'FF_SOURCE': 'CHARMM-GUI', 'FF_DATE': '??', 'TRJ': 'dope.trr', 'TPR': 'dope.tpr'}]\n"
     ]
    }
   ],
   "source": [
    "bNMRLIPIDS = False #Check if the link contains NMRLIPIDS metadata\n",
    "nsims =0 # Counter number of simulations in a submission\n",
    "sims = [] #Array with the dictionary containing the information of a simulation\n",
    "\n",
    "for line in user_information.split(\"\\n\"):\n",
    "    if line.strip() == \"\":\n",
    "        continue\n",
    "    if \"#NMRLIPIDS BEGIN\" in line:\n",
    "        bNMRLIPIDS = True\n",
    "        continue\n",
    "    if \"#NMRLIPIDS END\" in line:\n",
    "        bNMRLIPIDS = False\n",
    "        continue\n",
    "    if \"@SIM\" in line:\n",
    "        #sims.append({\"ID\" : nsims, \"STATUS\" : 0})\n",
    "        sims.append({\"ID\" : nsims})\n",
    "        nsims += 1\n",
    "        continue\n",
    "    if not bNMRLIPIDS:\n",
    "        continue\n",
    "    if line.strip()[0] == \"@\":\n",
    "        key, value = line.split(\"=\")\n",
    "        sims[-1][key.strip('@')] = value\n",
    "print(nsims)\n",
    "print(sims)      \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['GROMACS', 'AMBER', 'NAMD', 'CHARMM', 'OPENMM'])\n"
     ]
    }
   ],
   "source": [
    "# Gromacs\n",
    "gromacs_dict = {\n",
    "               'INI' : {\"REQUIRED\": False,\n",
    "                        \"TYPE\" : \"files\",\n",
    "                        \"EXTENSION\" : (\"gro\", \"pdb\",),\n",
    "                       }, # Could be not needed in the future (tpr)\n",
    "               'MDP' : {\"REQUIRED\": False,\n",
    "                        \"TYPE\" : \"file\",\n",
    "                        \"EXTENSION\" : (\"mdp\",),\n",
    "                       }, # Could be not needed in the future (tpr)\n",
    "               'TRJ' : {\"REQUIRED\": True,\n",
    "                        \"TYPE\" : \"files\",\n",
    "                        \"EXTENSION\" : (\"xtc\",\"trr\",),\n",
    "                       },\n",
    "               'TPR' : {\"REQUIRED\": True,\n",
    "                        \"TYPE\" : \"file\",\n",
    "                        \"EXTENSION\" : (\"tpr\",),\n",
    "                       },\n",
    "               'CPT' : {\"REQUIRED\": False,\n",
    "                        \"TYPE\" : \"file\",\n",
    "                        \"EXTENSION\" : (\"cpt\",),\n",
    "                       },\n",
    "               'TOP' : {\"REQUIRED\": False,\n",
    "                        \"TYPE\" : \"file\",\n",
    "                        \"EXTENSION\" : (\"top\",),\n",
    "                       },\n",
    "               'ITP' : {\"REQUIRED\": False,\n",
    "                        \"TYPE\" : \"files\",\n",
    "                        \"EXTENSION\" : (\"itp\",),\n",
    "                       },\n",
    "               'FF'  : {\"REQUIRED\": False,\n",
    "                        \"TYPE\" : \"string\",\n",
    "                       },\n",
    "               'FF_SOURCE' : {\"REQUIRED\": False,\n",
    "                              \"TYPE\" : \"string\",\n",
    "                              },\n",
    "               'FF_DATE' : {\"REQUIRED\": False,\n",
    "                            \"TYPE\" : \"date\",\n",
    "                           },\n",
    "               }\n",
    "\n",
    "# Amber\n",
    "amber_dict = {}\n",
    "\n",
    "# NAMD\n",
    "namd_dict = {}\n",
    "\n",
    "# CHARMM\n",
    "charmm_dict = {}\n",
    "\n",
    "# OPENMM\n",
    "openmm_dict = {}\n",
    "\n",
    "# SOFTWARE\n",
    "software_dict = {\n",
    "                \"GROMACS\" : gromacs_dict, \n",
    "                \"AMBER\"   : amber_dict,\n",
    "                \"NAMD\"    : namd_dict,\n",
    "                \"CHARMM\"  : charmm_dict,\n",
    "                \"OPENMM\"  : openmm_dict,\n",
    "                }\n",
    "\n",
    "print(software_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check software used by the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 uses supported software GROMACS and will be further processed\n"
     ]
    }
   ],
   "source": [
    "sims_valid_software = []\n",
    "for sim in sims:\n",
    "    if sim['SOFTWARE'].upper() in software_dict.keys():\n",
    "        msg_info = \"Simulation {0} uses supported software {1} and will be further processed\"\n",
    "        print (msg_info.format(sim['ID'], sim['SOFTWARE'].upper()))\n",
    "        sims_valid_software.append(sim.copy())\n",
    "    else:\n",
    "        msg_err=\"Simulation {0} performed in an UNSUPPORTED software {1} and will NOT be further processed\"\n",
    "        print(msg_err.format(sim[\"ID\"], sim[\"SOFTWARE\"].upper()))\n",
    "#print(sims_valid_software) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that all entry keys provided for each simulation are valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entries in simulation 0 are understood and will be further processed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sims_valid_entries = []\n",
    "for sim in sims_valid_software:\n",
    "    #print(\"ID {0}\".format(sim[\"ID\"]))\n",
    "    wrong_key_entries = 0\n",
    "    software_dict_name = \"{0}_dict\".format(sim['SOFTWARE'].lower())\n",
    "    for key_sim, value_sim in sim.items():\n",
    "        #print(key_sim, value_sim)\n",
    "        if key_sim.upper() in (\"ID\", \"SOFTWARE\"):\n",
    "            #print(\"NOT REQUIRED\")\n",
    "            continue\n",
    "        if key_sim.upper() not in software_dict[sim['SOFTWARE'].upper()].keys():\n",
    "            print (\"{0} NOT in {1}\".format(key_sim, software_dict_name))\n",
    "            wrong_key_entries += 1\n",
    "    if wrong_key_entries:\n",
    "        print(\"Simulation {0} has {1} unknown entry/ies and won't be longer considered, please correct.\\n\".format(sim['ID'],wrong_key_entries))\n",
    "    else:\n",
    "        msg_info = \"All entries in simulation {0} are understood and will be further processed\\n\"\n",
    "        print (msg_info.format(sim['ID']))\n",
    "        sims_valid_entries.append(sim.copy())\n",
    "#print(sims_valid_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process entries with files information to contain file names in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 0\n",
      "dope.trr added to list\n",
      "dope.tpr added to list\n"
     ]
    }
   ],
   "source": [
    "sims_files_to_array = deepcopy(sims_valid_entries)\n",
    "\n",
    "for sim in sims_files_to_array:\n",
    "    print(\"ID {0}\".format(sim[\"ID\"]), flush=True)\n",
    "    software_sim = software_dict[sim['SOFTWARE'].upper()]\n",
    "    for key_sim, value_sim in sim.items():\n",
    "        try:\n",
    "            entry_type = software_sim[key_sim]['TYPE']\n",
    "            if \"file\" in entry_type:\n",
    "                if isinstance(value_sim, list): continue  \n",
    "                files_list = []\n",
    "                print(\"{0} added to list\".format(value_sim))\n",
    "                # Place filenames into arrays\n",
    "                for file_provided in value_sim.split(\";\"):\n",
    "                    files_list.append([file_provided.strip()])\n",
    "                sim[key_sim] = files_list\n",
    "        except: #It is notmal that fails for \"ID\" and \"SOFTWARE\"\n",
    "            continue\n",
    "#print(sims_files_to_array)\n",
    "#print(sims_valid_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for multiple files in entries that can only contain one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 0\n"
     ]
    }
   ],
   "source": [
    "sims_valid_file_entries = []\n",
    "for sim in sims_files_to_array:\n",
    "    print(\"ID {0}\".format(sim[\"ID\"]), flush=True)\n",
    "    files_issues = 0\n",
    "    software_sim = software_dict[sim['SOFTWARE'].upper()]\n",
    "    for key_sim, value_sim in sim.items():\n",
    "        try:\n",
    "            entry_type = software_sim[key_sim]['TYPE']\n",
    "            if entry_type == \"file\"  and len(value_sim) > 1:\n",
    "                print(\"Multiple values found in {0} and only one allowed (Please correct):\\n {1}\".format(key_sim,value_sim))\n",
    "                files_issues += 1\n",
    "        except: #It is notmal that fails for \"ID\" and \"SOFTWARE\"\n",
    "            continue\n",
    "    if files_issues:\n",
    "        print(\"Sim {0} will be no longer processed\".format(sim[\"ID\"]))\n",
    "    else:\n",
    "        sims_valid_file_entries.append(sim.copy())\n",
    "#print(sims_valid_file_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the submitted simulation has rssion has all required files and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 0\n",
      "All required entries present.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sims_required_entries = []\n",
    "for sim in sims_valid_file_entries:\n",
    "    print(\"ID {0}\".format(sim[\"ID\"]))\n",
    "    missing_required_keys = 0\n",
    "    for key, value in software_dict[sim['SOFTWARE'].upper()].items():\n",
    "        if value[\"REQUIRED\"]:\n",
    "            try:\n",
    "                sim[key]\n",
    "            except:\n",
    "                print(\"Entry not found: {0} {1}\".format(key, value))\n",
    "                missing_required_keys += 1\n",
    "    if missing_required_keys:\n",
    "        print(\"{0} missing required entry/ies, please correct.\".format(missing_required_keys))\n",
    "        print(\"Entry with ID={0} will not be further processed.\\n\".format(sim[\"ID\"]))\n",
    "    else:\n",
    "        print(\"All required entries present.\\n\")\n",
    "        sims_required_entries.append(sim.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check status links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download link\n",
    "def download_link(doi, file):\n",
    "    if \"zenodo\" in doi.lower():\n",
    "        zenodo_entry_number = doi.split(\".\")[2]\n",
    "        return 'https://zenodo.org/record/' + zenodo_entry_number + '/files/' + file\n",
    "    else:\n",
    "        print (\"DOI provided: {0}\".format(doi))\n",
    "        print (\"Repository not validated. Please upload the data for example to zenodo.org\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 0\n",
      "All links work.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(sims_required_entries)\n",
    "sims_working_links = []         \n",
    "for sim in sims_required_entries:\n",
    "    print(\"ID {0}\".format(sim[\"ID\"]))\n",
    "    wrong_links = 0\n",
    "    software_sim = software_dict[sim['SOFTWARE'].upper()]\n",
    "    for key_sim, value_sim in sim.items():\n",
    "        #print(\"key_sim = {0} => value_sim = {1}\".format(key_sim, value_sim))\n",
    "        try:\n",
    "            entry_type = software_sim[key_sim]['TYPE']\n",
    "            #print(\"entry_type = {0}\".format(entry_type))\n",
    "            if \"file\" in entry_type:\n",
    "                for file_provided in value_sim:\n",
    "                    #print(\"File={0}\".format(file_provided[0]))\n",
    "                    file_url = download_link(DOI, file_provided[0])\n",
    "                    if file_url == \"\":\n",
    "                        wrong_links += 1\n",
    "                        continue\n",
    "                    try:\n",
    "                        response = urllib.request.urlopen(file_url)\n",
    "                        #print(\"Status of the DOI link: {0}\".format(response.msg))\n",
    "                    except HTTPError as e:\n",
    "                        print(\"\\nkey={0} => file={1}\".format(key_sim, file_provided[0]))\n",
    "                        print(file_url)\n",
    "                        print('The server couldn\\'t fulfill the request.')\n",
    "                        print('Error code: ', e.code)\n",
    "                        wrong_links += 1\n",
    "                    except URLError as e:\n",
    "                        print(key_sim, file_provided[0])\n",
    "                        print(file_url)\n",
    "                        print('We failed to reach a server.')\n",
    "                        print('Reason: ', e.reason)\n",
    "                        wrong_links += 1\n",
    "                    else:\n",
    "                        pass\n",
    "        except: #It is notmal that fails for \"ID\" and \"SOFTWARE\"\n",
    "            continue\n",
    "    if wrong_links:\n",
    "        print(\"{0} link/s failed, please correct.\".format(wrong_links))\n",
    "        print(\"Sim={0} will not be further processed.\\n\".format(sim[\"ID\"]))\n",
    "    else:\n",
    "        print(\"All links work.\\n\")\n",
    "        sims_working_links.append(sim.copy())\n",
    "#print(sims_working_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files from links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRJ: 100%|██████████| 1/1 [05:04<00:00, 304.34s/it]\n",
      "TPR: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create temporary directory where to download files and analyze them\n",
    "dir_tmp = os.path.join(dir_wrk, \"tmp/\")\n",
    "if (not os.path.isdir(dir_tmp)): os.mkdir(dir_tmp)\n",
    "\n",
    "for sim in sims_working_links:\n",
    "    print(\"ID {0}\".format(sim[\"ID\"]), flush=True)\n",
    "    software_sim = software_dict[sim['SOFTWARE'].upper()]\n",
    "    dir_sim = os.path.join(dir_tmp, str(sim[\"ID\"]))\n",
    "    if (not os.path.isdir(dir_sim)): os.mkdir(dir_sim)\n",
    "    for key_sim, value_sim in sim.items():\n",
    "        #print(\"key_sim = {0} => value_sim = {1}\".format(key_sim, value_sim))\n",
    "        try:\n",
    "            entry_type = software_sim[key_sim]['TYPE']\n",
    "            #print(\"entry_type = {0}\".format(entry_type))\n",
    "            if \"file\" in entry_type:\n",
    "                for file_provided in tqdm(value_sim, desc = key_sim):\n",
    "                    file_url = download_link(DOI, file_provided[0])\n",
    "                    file_name = os.path.join(dir_sim, file_provided[0])\n",
    "                    if (not os.path.isfile(file_name)):\n",
    "                        response = urllib.request.urlretrieve(file_url, file_name)\n",
    "        except: #It is notmal that fails for \"ID\" and \"SOFTWARE\"\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate hash downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 0\n",
      "       NAME TYPE REQUIRED                                      HASH\n",
      "0  dope.trr  TRJ     True  e228e0e15becc30a6870ef7f0d6261e7c7eafd4c\n",
      "1  dope.tpr  TPR     True  5095cc60210597caff7914ea1e9ddd7beaeb6043\n",
      "\n",
      "['e228e0e15becc30a6870ef7f0d6261e7c7eafd4c', '5095cc60210597caff7914ea1e9ddd7beaeb6043']\n",
      "\n",
      "[{'ID': 0, 'SOFTWARE': 'gromacs', 'FF': 'CHARMM36', 'FF_SOURCE': 'CHARMM-GUI', 'FF_DATE': '??', 'TRJ': [['dope.trr', 'e228e0e15becc30a6870ef7f0d6261e7c7eafd4c']], 'TPR': [['dope.tpr', '5095cc60210597caff7914ea1e9ddd7beaeb6043']]}]\n"
     ]
    }
   ],
   "source": [
    "dir_tmp = os.path.join(dir_wrk, \"tmp/\")\n",
    "sims_hashes = deepcopy(sims_working_links)\n",
    "\n",
    "for sim in sims_hashes:\n",
    "    print(\"ID {0}\".format(sim[\"ID\"]), flush=True)\n",
    "    software_sim = software_dict[sim['SOFTWARE'].upper()]\n",
    "    dir_sim = os.path.join(dir_tmp, str(sim[\"ID\"]))\n",
    "    \n",
    "    #list_containing the sha1 sums for all required files\n",
    "    sha1_list_requied = []\n",
    "    \n",
    "    # Make empty dataframe with the desired columns\n",
    "    df_files = pd.DataFrame(columns=['NAME','TYPE','REQUIRED','HASH'])\n",
    "    \n",
    "    for key_sim, value_sim in sim.items():\n",
    "        #print(\"key_sim = {0} => value_sim = {1}\".format(key_sim, value_sim))\n",
    "        try:\n",
    "            entry_type = software_sim[key_sim]['TYPE']\n",
    "            #print(\"entry_type = {0}\".format(entry_type))\n",
    "            if \"file\" in entry_type:\n",
    "                files_list = []\n",
    "                for file_provided in value_sim:\n",
    "                    file_name = os.path.join(dir_sim, file_provided[0])\n",
    "                    sha1_hash = hashlib.sha1()\n",
    "                    with open(file_name,\"rb\") as f:\n",
    "                        # Read and update hash string value in blocks of 4K\n",
    "                        for byte_block in iter(lambda: f.read(4096),b\"\"):\n",
    "                            sha1_hash.update(byte_block)\n",
    "                        #print(file_provided, sha256_hash.hexdigest())\n",
    "                        df_files = df_files.append({\n",
    "                            \"NAME\":file_provided[0],\n",
    "                            \"TYPE\":key_sim,\n",
    "                            \"REQUIRED\": software_dict[sim['SOFTWARE'].upper()][key_sim]['REQUIRED'],\n",
    "                            \"HASH\":sha1_hash.hexdigest(),\n",
    "                        }, ignore_index=True)\n",
    "                    files_list.append([file_provided[0], sha1_hash.hexdigest()])\n",
    "                #Find the keys of the required files to calculate the master_hash \n",
    "                if software_dict[sim['SOFTWARE'].upper()][key_sim]['REQUIRED'] == True:\n",
    "                    sha1_list_requied.append(sha1_hash.hexdigest())\n",
    "                sim[key_sim] = files_list #Problematic\n",
    "        except: #It is notmal that fails for \"ID\" and \"SOFTWARE\"\n",
    "            continue\n",
    "    print(df_files)\n",
    "    print(\"\\n{0}\\n\".format(sha1_list_requied))      \n",
    "    # Calculate the hash of a file contaning the hashes of each of the required files\n",
    "    # This should be always invariant as it will be used unique identifier for a simualtion\n",
    "    # Note order the hashes of the required files before calculating the hash (That means that the required files cannot change)\n",
    "print(sims_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'ID': 0, 'SOFTWARE': 'gromacs', 'FF': 'CHARMM36', 'FF_SOURCE': 'CHARMM-GUI', 'FF_DATE': '??', 'TRJ': [['dope.trr']], 'TPR': [['dope.tpr']]}]\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(sims_working_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to databank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../Data/Simulations/10.5281:zenodo.3557459.0’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "for sim in sims_working_links:\n",
    "    ID=sim.get('ID')\n",
    "    # SAMULI: I replace \"/\" with \":\" because the former cannot be used in trajectory name\n",
    "    DATAdir='../Data/Simulations/'+str(DOI.replace(\"/\",\":\"))+'.'+str(ID)\n",
    "    !mkdir {DATAdir}\n",
    "    # SAMULI: I am writin now in txt, but using json might be better in the future\n",
    "    outfileDICT=open(str(DATAdir)+'/README.md','w')\n",
    "    outfileDICT.write(str(sim))\n",
    "    outfileDICT.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis starts here\n",
    "## First dowload packages and calculate the correlation functions using gromacs tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     :-) GROMACS - gmx trjconv, 2018.2 (-:\n",
      "\n",
      "                            GROMACS is written by:\n",
      "     Emile Apol      Rossen Apostolov      Paul Bauer     Herman J.C. Berendsen\n",
      "    Par Bjelkmar    Aldert van Buuren   Rudi van Drunen     Anton Feenstra  \n",
      "  Gerrit Groenhof    Aleksei Iupinov   Christoph Junghans   Anca Hamuraru   \n",
      " Vincent Hindriksen Dimitrios Karkoulis    Peter Kasson        Jiri Kraus    \n",
      "  Carsten Kutzner      Per Larsson      Justin A. Lemkul    Viveca Lindahl  \n",
      "  Magnus Lundborg   Pieter Meulenhoff    Erik Marklund      Teemu Murtola   \n",
      "    Szilard Pall       Sander Pronk      Roland Schulz     Alexey Shvetsov  \n",
      "   Michael Shirts     Alfons Sijbers     Peter Tieleman    Teemu Virolainen \n",
      " Christian Wennberg    Maarten Wolf   \n",
      "                           and the project leaders:\n",
      "        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel\n",
      "\n",
      "Copyright (c) 1991-2000, University of Groningen, The Netherlands.\n",
      "Copyright (c) 2001-2017, The GROMACS development team at\n",
      "Uppsala University, Stockholm University and\n",
      "the Royal Institute of Technology, Sweden.\n",
      "check out http://www.gromacs.org for more information.\n",
      "\n",
      "GROMACS is free software; you can redistribute it and/or modify it\n",
      "under the terms of the GNU Lesser General Public License\n",
      "as published by the Free Software Foundation; either version 2.1\n",
      "of the License, or (at your option) any later version.\n",
      "\n",
      "GROMACS:      gmx trjconv, version 2018.2\n",
      "Executable:   /home/local/osollila/gromacs/gromacs2018bin/bin/gmx\n",
      "Data prefix:  /home/local/osollila/gromacs/gromacs2018bin\n",
      "Working dir:  /home/local/osollila/NMRlipids/NMRlipidsVIpolarizableFFs/scripts\n",
      "Command line:\n",
      "  gmx trjconv -f /media/osollila/DATADRIVE1/temp3/tmp/0/dope.trr -s /media/osollila/DATADRIVE1/temp3/tmp/0/dope.tpr -o /media/osollila/DATADRIVE1/temp3/tmp/0/whole.xtc -pbc mol\n",
      "\n",
      "Will write xtc: Compressed trajectory (portable xdr format): xtc\n",
      "Reading file /media/osollila/DATADRIVE1/temp3/tmp/0/dope.tpr, VERSION 5.1.2 (single precision)\n",
      "Reading file /media/osollila/DATADRIVE1/temp3/tmp/0/dope.tpr, VERSION 5.1.2 (single precision)\n",
      "Select group for output\n",
      "Group     0 (         System) has 29952 elements\n",
      "Group     1 (          Other) has 29952 elements\n",
      "Group     2 (           DOPE) has 16512 elements\n",
      "Group     3 (           TIP3) has 13440 elements\n",
      "Select a group: Selected 0: 'System'\n",
      "trr version: GMX_trn_file (single precision)\n",
      "Reading frame       0 time    0.000   \n",
      "Setting output precision to 0.001 (nm)\n",
      "\n",
      "Back Off! I just backed up /media/osollila/DATADRIVE1/temp3/tmp/0/whole.xtc to /media/osollila/DATADRIVE1/temp3/tmp/0/#whole.xtc.2#\n",
      "Last frame      10000 time 500000.000    ->  frame  10000 time 500000.000      \n",
      "\n",
      "\n",
      "GROMACS reminds you: \"Make the Floor Burn\" (2 Unlimited)\n",
      "\n",
      "0 128\n",
      "beta1 1\n",
      "beta1 2\n",
      "beta1 3\n",
      "beta1 4\n",
      "beta1 5\n",
      "beta1 6\n",
      "beta1 7\n",
      "beta1 8\n",
      "beta1 9\n",
      "beta1 10\n",
      "beta1 11\n",
      "beta1 12\n",
      "beta1 13\n",
      "beta1 14\n",
      "beta1 15\n",
      "beta1 16\n",
      "beta1 17\n",
      "beta1 18\n",
      "beta1 19\n",
      "beta1 20\n",
      "beta1 21\n",
      "beta1 22\n",
      "beta1 23\n",
      "beta1 24\n",
      "beta1 25\n",
      "beta1 26\n",
      "beta1 27\n",
      "beta1 28\n",
      "beta1 29\n",
      "beta1 30\n",
      "beta1 31\n",
      "beta1 32\n",
      "beta1 33\n",
      "beta1 34\n",
      "beta1 35\n",
      "beta1 36\n",
      "beta1 37\n",
      "beta1 38\n",
      "beta1 39\n",
      "beta1 40\n",
      "beta1 41\n",
      "beta1 42\n",
      "beta1 43\n",
      "beta1 44\n",
      "beta1 45\n",
      "beta1 46\n",
      "beta1 47\n",
      "beta1 48\n",
      "beta1 49\n",
      "beta1 50\n",
      "beta1 51\n",
      "beta1 52\n",
      "beta1 53\n",
      "beta1 54\n",
      "beta1 55\n",
      "beta1 56\n",
      "beta1 57\n",
      "beta1 58\n",
      "beta1 59\n",
      "beta1 60\n",
      "beta1 61\n",
      "beta1 62\n",
      "beta1 63\n",
      "beta1 64\n",
      "beta1 65\n",
      "beta1 66\n",
      "beta1 67\n",
      "beta1 68\n",
      "beta1 69\n",
      "beta1 70\n",
      "beta1 71\n",
      "beta1 72\n",
      "beta1 73\n",
      "beta1 74\n",
      "beta1 75\n",
      "beta1 76\n",
      "beta1 77\n",
      "beta1 78\n",
      "beta1 79\n",
      "beta1 80\n",
      "beta1 81\n",
      "beta1 82\n",
      "beta1 83\n",
      "beta1 84\n",
      "beta1 85\n",
      "beta1 86\n",
      "beta1 87\n",
      "beta1 88\n",
      "beta1 89\n",
      "beta1 90\n",
      "beta1 91\n",
      "beta1 92\n",
      "beta1 93\n",
      "beta1 94\n",
      "beta1 95\n",
      "beta1 96\n",
      "beta1 97\n",
      "beta1 98\n",
      "beta1 99\n",
      "beta1 100\n",
      "beta1 101\n",
      "beta1 102\n",
      "beta1 103\n",
      "beta1 104\n",
      "beta1 105\n",
      "beta1 106\n",
      "beta1 107\n",
      "beta1 108\n",
      "beta1 109\n",
      "beta1 110\n",
      "beta1 111\n",
      "beta1 112\n",
      "beta1 113\n",
      "beta1 114\n",
      "beta1 115\n",
      "beta1 116\n",
      "beta1 117\n",
      "beta1 118\n",
      "beta1 119\n",
      "beta1 120\n",
      "beta1 121\n",
      "beta1 122\n",
      "beta1 123\n",
      "beta1 124\n",
      "beta1 125\n",
      "beta1 126\n",
      "beta1 127\n",
      "beta1 128\n",
      "beta2 1\n",
      "beta2 2\n",
      "beta2 3\n",
      "beta2 4\n",
      "beta2 5\n",
      "beta2 6\n",
      "beta2 7\n",
      "beta2 8\n",
      "beta2 9\n",
      "beta2 10\n",
      "beta2 11\n",
      "beta2 12\n",
      "beta2 13\n",
      "beta2 14\n",
      "beta2 15\n",
      "beta2 16\n",
      "beta2 17\n",
      "beta2 18\n",
      "beta2 19\n",
      "beta2 20\n",
      "beta2 21\n",
      "beta2 22\n",
      "beta2 23\n",
      "beta2 24\n",
      "beta2 25\n",
      "beta2 26\n",
      "beta2 27\n",
      "beta2 28\n",
      "beta2 29\n",
      "beta2 30\n",
      "beta2 31\n",
      "beta2 32\n",
      "beta2 33\n",
      "beta2 34\n",
      "beta2 35\n",
      "beta2 36\n",
      "beta2 37\n",
      "beta2 38\n",
      "beta2 39\n",
      "beta2 40\n",
      "beta2 41\n",
      "beta2 42\n",
      "beta2 43\n",
      "beta2 44\n",
      "beta2 45\n",
      "beta2 46\n",
      "beta2 47\n",
      "beta2 48\n",
      "beta2 49\n",
      "beta2 50\n",
      "beta2 51\n",
      "beta2 52\n",
      "beta2 53\n",
      "beta2 54\n",
      "beta2 55\n",
      "beta2 56\n",
      "beta2 57\n",
      "beta2 58\n",
      "beta2 59\n",
      "beta2 60\n",
      "beta2 61\n",
      "beta2 62\n",
      "beta2 63\n",
      "beta2 64\n",
      "beta2 65\n",
      "beta2 66\n",
      "beta2 67\n",
      "beta2 68\n",
      "beta2 69\n",
      "beta2 70\n",
      "beta2 71\n",
      "beta2 72\n",
      "beta2 73\n",
      "beta2 74\n",
      "beta2 75\n",
      "beta2 76\n",
      "beta2 77\n",
      "beta2 78\n",
      "beta2 79\n",
      "beta2 80\n",
      "beta2 81\n",
      "beta2 82\n",
      "beta2 83\n",
      "beta2 84\n",
      "beta2 85\n",
      "beta2 86\n",
      "beta2 87\n",
      "beta2 88\n",
      "beta2 89\n",
      "beta2 90\n",
      "beta2 91\n",
      "beta2 92\n",
      "beta2 93\n",
      "beta2 94\n",
      "beta2 95\n",
      "beta2 96\n",
      "beta2 97\n",
      "beta2 98\n",
      "beta2 99\n",
      "beta2 100\n",
      "beta2 101\n",
      "beta2 102\n",
      "beta2 103\n",
      "beta2 104\n",
      "beta2 105\n",
      "beta2 106\n",
      "beta2 107\n",
      "beta2 108\n",
      "beta2 109\n",
      "beta2 110\n",
      "beta2 111\n",
      "beta2 112\n",
      "beta2 113\n",
      "beta2 114\n",
      "beta2 115\n",
      "beta2 116\n",
      "beta2 117\n",
      "beta2 118\n",
      "beta2 119\n",
      "beta2 120\n",
      "beta2 121\n",
      "beta2 122\n",
      "beta2 123\n",
      "beta2 124\n",
      "beta2 125\n",
      "beta2 126\n",
      "beta2 127\n",
      "beta2 128\n",
      "alpha1 1\n",
      "alpha1 2\n",
      "alpha1 3\n",
      "alpha1 4\n",
      "alpha1 5\n",
      "alpha1 6\n",
      "alpha1 7\n",
      "alpha1 8\n",
      "alpha1 9\n",
      "alpha1 10\n",
      "alpha1 11\n",
      "alpha1 12\n",
      "alpha1 13\n",
      "alpha1 14\n",
      "alpha1 15\n",
      "alpha1 16\n",
      "alpha1 17\n",
      "alpha1 18\n",
      "alpha1 19\n",
      "alpha1 20\n",
      "alpha1 21\n",
      "alpha1 22\n",
      "alpha1 23\n",
      "alpha1 24\n",
      "alpha1 25\n",
      "alpha1 26\n",
      "alpha1 27\n",
      "alpha1 28\n",
      "alpha1 29\n",
      "alpha1 30\n",
      "alpha1 31\n",
      "alpha1 32\n",
      "alpha1 33\n",
      "alpha1 34\n",
      "alpha1 35\n",
      "alpha1 36\n",
      "alpha1 37\n",
      "alpha1 38\n",
      "alpha1 39\n",
      "alpha1 40\n",
      "alpha1 41\n",
      "alpha1 42\n",
      "alpha1 43\n",
      "alpha1 44\n",
      "alpha1 45\n",
      "alpha1 46\n",
      "alpha1 47\n",
      "alpha1 48\n",
      "alpha1 49\n",
      "alpha1 50\n",
      "alpha1 51\n",
      "alpha1 52\n",
      "alpha1 53\n",
      "alpha1 54\n",
      "alpha1 55\n",
      "alpha1 56\n",
      "alpha1 57\n",
      "alpha1 58\n",
      "alpha1 59\n",
      "alpha1 60\n",
      "alpha1 61\n",
      "alpha1 62\n",
      "alpha1 63\n",
      "alpha1 64\n",
      "alpha1 65\n",
      "alpha1 66\n",
      "alpha1 67\n",
      "alpha1 68\n",
      "alpha1 69\n",
      "alpha1 70\n",
      "alpha1 71\n",
      "alpha1 72\n",
      "alpha1 73\n",
      "alpha1 74\n",
      "alpha1 75\n",
      "alpha1 76\n",
      "alpha1 77\n",
      "alpha1 78\n",
      "alpha1 79\n",
      "alpha1 80\n",
      "alpha1 81\n",
      "alpha1 82\n",
      "alpha1 83\n",
      "alpha1 84\n",
      "alpha1 85\n",
      "alpha1 86\n",
      "alpha1 87\n",
      "alpha1 88\n",
      "alpha1 89\n",
      "alpha1 90\n",
      "alpha1 91\n",
      "alpha1 92\n",
      "alpha1 93\n",
      "alpha1 94\n",
      "alpha1 95\n",
      "alpha1 96\n",
      "alpha1 97\n",
      "alpha1 98\n",
      "alpha1 99\n",
      "alpha1 100\n",
      "alpha1 101\n",
      "alpha1 102\n",
      "alpha1 103\n",
      "alpha1 104\n",
      "alpha1 105\n",
      "alpha1 106\n",
      "alpha1 107\n",
      "alpha1 108\n",
      "alpha1 109\n",
      "alpha1 110\n",
      "alpha1 111\n",
      "alpha1 112\n",
      "alpha1 113\n",
      "alpha1 114\n",
      "alpha1 115\n",
      "alpha1 116\n",
      "alpha1 117\n",
      "alpha1 118\n",
      "alpha1 119\n",
      "alpha1 120\n",
      "alpha1 121\n",
      "alpha1 122\n",
      "alpha1 123\n",
      "alpha1 124\n",
      "alpha1 125\n",
      "alpha1 126\n",
      "alpha1 127\n",
      "alpha1 128\n",
      "alpha2 1\n",
      "alpha2 2\n",
      "alpha2 3\n",
      "alpha2 4\n",
      "alpha2 5\n",
      "alpha2 6\n",
      "alpha2 7\n",
      "alpha2 8\n",
      "alpha2 9\n",
      "alpha2 10\n",
      "alpha2 11\n",
      "alpha2 12\n",
      "alpha2 13\n",
      "alpha2 14\n",
      "alpha2 15\n",
      "alpha2 16\n",
      "alpha2 17\n",
      "alpha2 18\n",
      "alpha2 19\n",
      "alpha2 20\n",
      "alpha2 21\n",
      "alpha2 22\n",
      "alpha2 23\n",
      "alpha2 24\n",
      "alpha2 25\n",
      "alpha2 26\n",
      "alpha2 27\n",
      "alpha2 28\n",
      "alpha2 29\n",
      "alpha2 30\n",
      "alpha2 31\n",
      "alpha2 32\n",
      "alpha2 33\n",
      "alpha2 34\n",
      "alpha2 35\n",
      "alpha2 36\n",
      "alpha2 37\n",
      "alpha2 38\n",
      "alpha2 39\n",
      "alpha2 40\n",
      "alpha2 41\n",
      "alpha2 42\n",
      "alpha2 43\n",
      "alpha2 44\n",
      "alpha2 45\n",
      "alpha2 46\n",
      "alpha2 47\n",
      "alpha2 48\n",
      "alpha2 49\n",
      "alpha2 50\n",
      "alpha2 51\n",
      "alpha2 52\n",
      "alpha2 53\n",
      "alpha2 54\n",
      "alpha2 55\n",
      "alpha2 56\n",
      "alpha2 57\n",
      "alpha2 58\n",
      "alpha2 59\n",
      "alpha2 60\n",
      "alpha2 61\n",
      "alpha2 62\n",
      "alpha2 63\n",
      "alpha2 64\n",
      "alpha2 65\n",
      "alpha2 66\n",
      "alpha2 67\n",
      "alpha2 68\n",
      "alpha2 69\n",
      "alpha2 70\n",
      "alpha2 71\n",
      "alpha2 72\n",
      "alpha2 73\n",
      "alpha2 74\n",
      "alpha2 75\n",
      "alpha2 76\n",
      "alpha2 77\n",
      "alpha2 78\n",
      "alpha2 79\n",
      "alpha2 80\n",
      "alpha2 81\n",
      "alpha2 82\n",
      "alpha2 83\n",
      "alpha2 84\n",
      "alpha2 85\n",
      "alpha2 86\n",
      "alpha2 87\n",
      "alpha2 88\n",
      "alpha2 89\n",
      "alpha2 90\n",
      "alpha2 91\n",
      "alpha2 92\n",
      "alpha2 93\n",
      "alpha2 94\n",
      "alpha2 95\n",
      "alpha2 96\n",
      "alpha2 97\n",
      "alpha2 98\n",
      "alpha2 99\n",
      "alpha2 100\n",
      "alpha2 101\n",
      "alpha2 102\n",
      "alpha2 103\n",
      "alpha2 104\n",
      "alpha2 105\n",
      "alpha2 106\n",
      "alpha2 107\n",
      "alpha2 108\n",
      "alpha2 109\n",
      "alpha2 110\n",
      "alpha2 111\n",
      "alpha2 112\n",
      "alpha2 113\n",
      "alpha2 114\n",
      "alpha2 115\n",
      "alpha2 116\n",
      "alpha2 117\n",
      "alpha2 118\n",
      "alpha2 119\n",
      "alpha2 120\n",
      "alpha2 121\n",
      "alpha2 122\n",
      "alpha2 123\n",
      "alpha2 124\n",
      "alpha2 125\n",
      "alpha2 126\n",
      "alpha2 127\n",
      "alpha2 128\n",
      "g3_1 1\n",
      "g3_1 2\n",
      "g3_1 3\n",
      "g3_1 4\n",
      "g3_1 5\n",
      "g3_1 6\n",
      "g3_1 7\n",
      "g3_1 8\n",
      "g3_1 9\n",
      "g3_1 10\n",
      "g3_1 11\n",
      "g3_1 12\n",
      "g3_1 13\n",
      "g3_1 14\n",
      "g3_1 15\n",
      "g3_1 16\n",
      "g3_1 17\n",
      "g3_1 18\n",
      "g3_1 19\n",
      "g3_1 20\n",
      "g3_1 21\n",
      "g3_1 22\n",
      "g3_1 23\n",
      "g3_1 24\n",
      "g3_1 25\n",
      "g3_1 26\n",
      "g3_1 27\n",
      "g3_1 28\n",
      "g3_1 29\n",
      "g3_1 30\n",
      "g3_1 31\n",
      "g3_1 32\n",
      "g3_1 33\n",
      "g3_1 34\n",
      "g3_1 35\n",
      "g3_1 36\n",
      "g3_1 37\n",
      "g3_1 38\n",
      "g3_1 39\n",
      "g3_1 40\n",
      "g3_1 41\n",
      "g3_1 42\n",
      "g3_1 43\n",
      "g3_1 44\n",
      "g3_1 45\n",
      "g3_1 46\n",
      "g3_1 47\n",
      "g3_1 48\n",
      "g3_1 49\n",
      "g3_1 50\n",
      "g3_1 51\n",
      "g3_1 52\n",
      "g3_1 53\n",
      "g3_1 54\n",
      "g3_1 55\n",
      "g3_1 56\n",
      "g3_1 57\n",
      "g3_1 58\n",
      "g3_1 59\n",
      "g3_1 60\n",
      "g3_1 61\n",
      "g3_1 62\n",
      "g3_1 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g3_1 64\n",
      "g3_1 65\n",
      "g3_1 66\n",
      "g3_1 67\n",
      "g3_1 68\n",
      "g3_1 69\n",
      "g3_1 70\n",
      "g3_1 71\n",
      "g3_1 72\n",
      "g3_1 73\n",
      "g3_1 74\n",
      "g3_1 75\n",
      "g3_1 76\n",
      "g3_1 77\n",
      "g3_1 78\n",
      "g3_1 79\n",
      "g3_1 80\n",
      "g3_1 81\n",
      "g3_1 82\n",
      "g3_1 83\n",
      "g3_1 84\n",
      "g3_1 85\n",
      "g3_1 86\n",
      "g3_1 87\n",
      "g3_1 88\n",
      "g3_1 89\n",
      "g3_1 90\n",
      "g3_1 91\n",
      "g3_1 92\n",
      "g3_1 93\n",
      "g3_1 94\n",
      "g3_1 95\n",
      "g3_1 96\n",
      "g3_1 97\n",
      "g3_1 98\n",
      "g3_1 99\n",
      "g3_1 100\n",
      "g3_1 101\n",
      "g3_1 102\n",
      "g3_1 103\n",
      "g3_1 104\n",
      "g3_1 105\n",
      "g3_1 106\n",
      "g3_1 107\n",
      "g3_1 108\n",
      "g3_1 109\n",
      "g3_1 110\n",
      "g3_1 111\n",
      "g3_1 112\n",
      "g3_1 113\n",
      "g3_1 114\n",
      "g3_1 115\n",
      "g3_1 116\n",
      "g3_1 117\n",
      "g3_1 118\n",
      "g3_1 119\n",
      "g3_1 120\n",
      "g3_1 121\n",
      "g3_1 122\n",
      "g3_1 123\n",
      "g3_1 124\n",
      "g3_1 125\n",
      "g3_1 126\n",
      "g3_1 127\n",
      "g3_1 128\n",
      "g3_2 1\n",
      "g3_2 2\n",
      "g3_2 3\n",
      "g3_2 4\n",
      "g3_2 5\n",
      "g3_2 6\n",
      "g3_2 7\n",
      "g3_2 8\n",
      "g3_2 9\n",
      "g3_2 10\n",
      "g3_2 11\n",
      "g3_2 12\n",
      "g3_2 13\n",
      "g3_2 14\n",
      "g3_2 15\n",
      "g3_2 16\n",
      "g3_2 17\n",
      "g3_2 18\n",
      "g3_2 19\n",
      "g3_2 20\n",
      "g3_2 21\n",
      "g3_2 22\n",
      "g3_2 23\n",
      "g3_2 24\n",
      "g3_2 25\n",
      "g3_2 26\n",
      "g3_2 27\n",
      "g3_2 28\n",
      "g3_2 29\n",
      "g3_2 30\n",
      "g3_2 31\n",
      "g3_2 32\n",
      "g3_2 33\n",
      "g3_2 34\n",
      "g3_2 35\n",
      "g3_2 36\n",
      "g3_2 37\n",
      "g3_2 38\n",
      "g3_2 39\n",
      "g3_2 40\n",
      "g3_2 41\n",
      "g3_2 42\n",
      "g3_2 43\n",
      "g3_2 44\n",
      "g3_2 45\n",
      "g3_2 46\n",
      "g3_2 47\n",
      "g3_2 48\n",
      "g3_2 49\n",
      "g3_2 50\n",
      "g3_2 51\n",
      "g3_2 52\n",
      "g3_2 53\n",
      "g3_2 54\n",
      "g3_2 55\n",
      "g3_2 56\n",
      "g3_2 57\n",
      "g3_2 58\n",
      "g3_2 59\n",
      "g3_2 60\n",
      "g3_2 61\n",
      "g3_2 62\n",
      "g3_2 63\n",
      "g3_2 64\n",
      "g3_2 65\n",
      "g3_2 66\n",
      "g3_2 67\n",
      "g3_2 68\n",
      "g3_2 69\n",
      "g3_2 70\n",
      "g3_2 71\n",
      "g3_2 72\n",
      "g3_2 73\n",
      "g3_2 74\n",
      "g3_2 75\n",
      "g3_2 76\n",
      "g3_2 77\n",
      "g3_2 78\n",
      "g3_2 79\n",
      "g3_2 80\n",
      "g3_2 81\n",
      "g3_2 82\n",
      "g3_2 83\n",
      "g3_2 84\n",
      "g3_2 85\n",
      "g3_2 86\n",
      "g3_2 87\n",
      "g3_2 88\n",
      "g3_2 89\n",
      "g3_2 90\n",
      "g3_2 91\n",
      "g3_2 92\n",
      "g3_2 93\n",
      "g3_2 94\n",
      "g3_2 95\n",
      "g3_2 96\n",
      "g3_2 97\n",
      "g3_2 98\n",
      "g3_2 99\n",
      "g3_2 100\n",
      "g3_2 101\n",
      "g3_2 102\n",
      "g3_2 103\n",
      "g3_2 104\n",
      "g3_2 105\n",
      "g3_2 106\n",
      "g3_2 107\n",
      "g3_2 108\n",
      "g3_2 109\n",
      "g3_2 110\n",
      "g3_2 111\n",
      "g3_2 112\n",
      "g3_2 113\n",
      "g3_2 114\n",
      "g3_2 115\n",
      "g3_2 116\n",
      "g3_2 117\n",
      "g3_2 118\n",
      "g3_2 119\n",
      "g3_2 120\n",
      "g3_2 121\n",
      "g3_2 122\n",
      "g3_2 123\n",
      "g3_2 124\n",
      "g3_2 125\n",
      "g3_2 126\n",
      "g3_2 127\n",
      "g3_2 128\n",
      "g2_1 1\n",
      "g2_1 2\n",
      "g2_1 3\n",
      "g2_1 4\n",
      "g2_1 5\n",
      "g2_1 6\n",
      "g2_1 7\n",
      "g2_1 8\n",
      "g2_1 9\n",
      "g2_1 10\n",
      "g2_1 11\n",
      "g2_1 12\n",
      "g2_1 13\n",
      "g2_1 14\n",
      "g2_1 15\n",
      "g2_1 16\n",
      "g2_1 17\n",
      "g2_1 18\n",
      "g2_1 19\n",
      "g2_1 20\n",
      "g2_1 21\n",
      "g2_1 22\n",
      "g2_1 23\n",
      "g2_1 24\n",
      "g2_1 25\n",
      "g2_1 26\n",
      "g2_1 27\n",
      "g2_1 28\n",
      "g2_1 29\n",
      "g2_1 30\n",
      "g2_1 31\n",
      "g2_1 32\n",
      "g2_1 33\n",
      "g2_1 34\n",
      "g2_1 35\n",
      "g2_1 36\n",
      "g2_1 37\n",
      "g2_1 38\n",
      "g2_1 39\n",
      "g2_1 40\n",
      "g2_1 41\n",
      "g2_1 42\n",
      "g2_1 43\n",
      "g2_1 44\n",
      "g2_1 45\n",
      "g2_1 46\n",
      "g2_1 47\n",
      "g2_1 48\n",
      "g2_1 49\n",
      "g2_1 50\n",
      "g2_1 51\n",
      "g2_1 52\n",
      "g2_1 53\n",
      "g2_1 54\n",
      "g2_1 55\n",
      "g2_1 56\n",
      "g2_1 57\n",
      "g2_1 58\n",
      "g2_1 59\n",
      "g2_1 60\n",
      "g2_1 61\n",
      "g2_1 62\n",
      "g2_1 63\n",
      "g2_1 64\n",
      "g2_1 65\n",
      "g2_1 66\n",
      "g2_1 67\n",
      "g2_1 68\n",
      "g2_1 69\n",
      "g2_1 70\n",
      "g2_1 71\n",
      "g2_1 72\n",
      "g2_1 73\n",
      "g2_1 74\n",
      "g2_1 75\n",
      "g2_1 76\n",
      "g2_1 77\n",
      "g2_1 78\n",
      "g2_1 79\n",
      "g2_1 80\n",
      "g2_1 81\n",
      "g2_1 82\n",
      "g2_1 83\n",
      "g2_1 84\n",
      "g2_1 85\n",
      "g2_1 86\n",
      "g2_1 87\n",
      "g2_1 88\n",
      "g2_1 89\n",
      "g2_1 90\n",
      "g2_1 91\n",
      "g2_1 92\n",
      "g2_1 93\n",
      "g2_1 94\n",
      "g2_1 95\n",
      "g2_1 96\n",
      "g2_1 97\n",
      "g2_1 98\n",
      "g2_1 99\n",
      "g2_1 100\n",
      "g2_1 101\n",
      "g2_1 102\n",
      "g2_1 103\n",
      "g2_1 104\n",
      "g2_1 105\n",
      "g2_1 106\n",
      "g2_1 107\n",
      "g2_1 108\n",
      "g2_1 109\n",
      "g2_1 110\n",
      "g2_1 111\n",
      "g2_1 112\n",
      "g2_1 113\n",
      "g2_1 114\n",
      "g2_1 115\n",
      "g2_1 116\n",
      "g2_1 117\n",
      "g2_1 118\n",
      "g2_1 119\n",
      "g2_1 120\n",
      "g2_1 121\n",
      "g2_1 122\n",
      "g2_1 123\n",
      "g2_1 124\n",
      "g2_1 125\n",
      "g2_1 126\n",
      "g2_1 127\n",
      "g2_1 128\n",
      "g1_1 1\n",
      "g1_1 2\n",
      "g1_1 3\n",
      "g1_1 4\n",
      "g1_1 5\n",
      "g1_1 6\n",
      "g1_1 7\n",
      "g1_1 8\n",
      "g1_1 9\n",
      "g1_1 10\n",
      "g1_1 11\n",
      "g1_1 12\n",
      "g1_1 13\n",
      "g1_1 14\n",
      "g1_1 15\n",
      "g1_1 16\n",
      "g1_1 17\n",
      "g1_1 18\n",
      "g1_1 19\n",
      "g1_1 20\n",
      "g1_1 21\n",
      "g1_1 22\n",
      "g1_1 23\n",
      "g1_1 24\n",
      "g1_1 25\n",
      "g1_1 26\n",
      "g1_1 27\n",
      "g1_1 28\n",
      "g1_1 29\n",
      "g1_1 30\n",
      "g1_1 31\n",
      "g1_1 32\n",
      "g1_1 33\n",
      "g1_1 34\n",
      "g1_1 35\n",
      "g1_1 36\n",
      "g1_1 37\n",
      "g1_1 38\n",
      "g1_1 39\n",
      "g1_1 40\n",
      "g1_1 41\n",
      "g1_1 42\n",
      "g1_1 43\n",
      "g1_1 44\n",
      "g1_1 45\n",
      "g1_1 46\n",
      "g1_1 47\n",
      "g1_1 48\n",
      "g1_1 49\n",
      "g1_1 50\n",
      "g1_1 51\n",
      "g1_1 52\n",
      "g1_1 53\n",
      "g1_1 54\n",
      "g1_1 55\n",
      "g1_1 56\n",
      "g1_1 57\n",
      "g1_1 58\n",
      "g1_1 59\n",
      "g1_1 60\n",
      "g1_1 61\n",
      "g1_1 62\n",
      "g1_1 63\n",
      "g1_1 64\n",
      "g1_1 65\n",
      "g1_1 66\n",
      "g1_1 67\n",
      "g1_1 68\n",
      "g1_1 69\n",
      "g1_1 70\n",
      "g1_1 71\n",
      "g1_1 72\n",
      "g1_1 73\n",
      "g1_1 74\n",
      "g1_1 75\n",
      "g1_1 76\n",
      "g1_1 77\n",
      "g1_1 78\n",
      "g1_1 79\n",
      "g1_1 80\n",
      "g1_1 81\n",
      "g1_1 82\n",
      "g1_1 83\n",
      "g1_1 84\n",
      "g1_1 85\n",
      "g1_1 86\n",
      "g1_1 87\n",
      "g1_1 88\n",
      "g1_1 89\n",
      "g1_1 90\n",
      "g1_1 91\n",
      "g1_1 92\n",
      "g1_1 93\n",
      "g1_1 94\n",
      "g1_1 95\n",
      "g1_1 96\n",
      "g1_1 97\n",
      "g1_1 98\n",
      "g1_1 99\n",
      "g1_1 100\n",
      "g1_1 101\n",
      "g1_1 102\n",
      "g1_1 103\n",
      "g1_1 104\n",
      "g1_1 105\n",
      "g1_1 106\n",
      "g1_1 107\n",
      "g1_1 108\n",
      "g1_1 109\n",
      "g1_1 110\n",
      "g1_1 111\n",
      "g1_1 112\n",
      "g1_1 113\n",
      "g1_1 114\n",
      "g1_1 115\n",
      "g1_1 116\n",
      "g1_1 117\n",
      "g1_1 118\n",
      "g1_1 119\n",
      "g1_1 120\n",
      "g1_1 121\n",
      "g1_1 122\n",
      "g1_1 123\n",
      "g1_1 124\n",
      "g1_1 125\n",
      "g1_1 126\n",
      "g1_1 127\n",
      "g1_1 128\n",
      "g1_2 1\n",
      "g1_2 2\n",
      "g1_2 3\n",
      "g1_2 4\n",
      "g1_2 5\n",
      "g1_2 6\n",
      "g1_2 7\n",
      "g1_2 8\n",
      "g1_2 9\n",
      "g1_2 10\n",
      "g1_2 11\n",
      "g1_2 12\n",
      "g1_2 13\n",
      "g1_2 14\n",
      "g1_2 15\n",
      "g1_2 16\n",
      "g1_2 17\n",
      "g1_2 18\n",
      "g1_2 19\n",
      "g1_2 20\n",
      "g1_2 21\n",
      "g1_2 22\n",
      "g1_2 23\n",
      "g1_2 24\n",
      "g1_2 25\n",
      "g1_2 26\n",
      "g1_2 27\n",
      "g1_2 28\n",
      "g1_2 29\n",
      "g1_2 30\n",
      "g1_2 31\n",
      "g1_2 32\n",
      "g1_2 33\n",
      "g1_2 34\n",
      "g1_2 35\n",
      "g1_2 36\n",
      "g1_2 37\n",
      "g1_2 38\n",
      "g1_2 39\n",
      "g1_2 40\n",
      "g1_2 41\n",
      "g1_2 42\n",
      "g1_2 43\n",
      "g1_2 44\n",
      "g1_2 45\n",
      "g1_2 46\n",
      "g1_2 47\n",
      "g1_2 48\n",
      "g1_2 49\n",
      "g1_2 50\n",
      "g1_2 51\n",
      "g1_2 52\n",
      "g1_2 53\n",
      "g1_2 54\n",
      "g1_2 55\n",
      "g1_2 56\n",
      "g1_2 57\n",
      "g1_2 58\n",
      "g1_2 59\n",
      "g1_2 60\n",
      "g1_2 61\n",
      "g1_2 62\n",
      "g1_2 63\n",
      "g1_2 64\n",
      "g1_2 65\n",
      "g1_2 66\n",
      "g1_2 67\n",
      "g1_2 68\n",
      "g1_2 69\n",
      "g1_2 70\n",
      "g1_2 71\n",
      "g1_2 72\n",
      "g1_2 73\n",
      "g1_2 74\n",
      "g1_2 75\n",
      "g1_2 76\n",
      "g1_2 77\n",
      "g1_2 78\n",
      "g1_2 79\n",
      "g1_2 80\n",
      "g1_2 81\n",
      "g1_2 82\n",
      "g1_2 83\n",
      "g1_2 84\n",
      "g1_2 85\n",
      "g1_2 86\n",
      "g1_2 87\n",
      "g1_2 88\n",
      "g1_2 89\n",
      "g1_2 90\n",
      "g1_2 91\n",
      "g1_2 92\n",
      "g1_2 93\n",
      "g1_2 94\n",
      "g1_2 95\n",
      "g1_2 96\n",
      "g1_2 97\n",
      "g1_2 98\n",
      "g1_2 99\n",
      "g1_2 100\n",
      "g1_2 101\n",
      "g1_2 102\n",
      "g1_2 103\n",
      "g1_2 104\n",
      "g1_2 105\n",
      "g1_2 106\n",
      "g1_2 107\n",
      "g1_2 108\n",
      "g1_2 109\n",
      "g1_2 110\n",
      "g1_2 111\n",
      "g1_2 112\n",
      "g1_2 113\n",
      "g1_2 114\n",
      "g1_2 115\n",
      "g1_2 116\n",
      "g1_2 117\n",
      "g1_2 118\n",
      "g1_2 119\n",
      "g1_2 120\n",
      "g1_2 121\n",
      "g1_2 122\n",
      "g1_2 123\n",
      "g1_2 124\n",
      "g1_2 125\n",
      "g1_2 126\n",
      "g1_2 127\n",
      "g1_2 128\n"
     ]
    }
   ],
   "source": [
    "from OrderParameter import *\n",
    "import warnings\n",
    "from corrtimes import *\n",
    "import subprocess\n",
    "!cp corr_ftios_ind.sh {dir_wrk}\n",
    "for sim in sims_working_links:\n",
    "    trj=sim.get('TRJ')\n",
    "    tpr=sim.get('TPR')\n",
    "    ID=sim.get('ID')\n",
    "    \n",
    "    #tprnowat=str(dir_wrk)+'/tmp/'+str(ID)+'/'+'nowater.tpr'\n",
    "    #xtcnowatwhole=str(dir_wrk)+'/tmp/'+str(ID)+'/'+'whole.xtc'\n",
    "    xtcwhole=str(dir_wrk)+'/tmp/'+str(ID)+'/'+'whole.xtc'\n",
    "    #trj='tmp/'+str(ID)+'/'+str(trj[0][0])\n",
    "    tpr=str(dir_wrk)+'/tmp/'+str(ID)+'/'+str(tpr[0][0])\n",
    "    #print(def_file,tpr,trj)\n",
    "\n",
    "    # SAMULI: line below could be removed by giving output folder for corr_ftios.sh\n",
    "    #!mv *rotacf*xvg {dir_wrk}/tmp/{ID}/\n",
    "    # SAMULI: line below could are because find_OP does not work for folders\n",
    "    #!cp {dir_wrk}/tmp/{ID}/{str(trj[0][0])} ./\n",
    "    #!cp {dir_wrk}/tmp/{ID}/{str(tpr[0][0])} ./\n",
    "    #Hanne: shortening the traj here for debugging \n",
    "    !echo System | gmx trjconv -f {dir_wrk}/tmp/{ID}/{str(trj[0][0])} -s {tpr} -o {xtcwhole} -pbc mol \n",
    "    # SAMULI: I compromized the speed to generality. Not all systems automatically have non-water group\n",
    "    #!echo non-water | gmx trjconv -f {dir_wrk}/tmp/{ID}/{str(trj[0][0])} -t0 0 -s {dir_wrk}/tmp/{ID}/{str(tpr[0][0])} -o {xtcnowatwhole} -pbc mol \n",
    "    #!echo non-Water | gmx trjconv -f tmp.trr -s {dir_wrk}/tmp/{ID}/{str(tpr[0][0])} -o {dir_wrk}/tmp/{ID}/whole.xtc -pbc mol \n",
    "    #!echo non-Water | gmx convert-tpr -s {dir_wrk}/tmp/{ID}/{str(tpr[0][0])} -o {tprnowat}\n",
    "    #!rm tmp.trr \n",
    "\n",
    "    \n",
    "    \n",
    "    output_corr=!{dir_wrk}/corr_ftios_ind.sh {def_file} {tpr} {xtcwhole} {dir_wrk}/tmp/{ID}\n",
    "    #tmp=output_corr.split()\n",
    "    #print (output_corr)\n",
    "    tmp=output_corr[-1].split()\n",
    "    \n",
    "    firstlipid=int(tmp[-2])\n",
    "    lastlipid=int(tmp[-1])\n",
    "    numlipid=lastlipid-firstlipid+1    \n",
    "    \n",
    "    print (ID, numlipid)\n",
    "    \n",
    "    \n",
    "    OrdParam=find_OP(def_file,tpr,xtcwhole)\n",
    "    outfile=open(str(dir_wrk)+'/tmp/'+str(ID)+'/'+'times'+str(ID)+'.txt','w')\n",
    "    outfile_teffs=open(str(dir_wrk)+'/tmp/'+str(ID)+'/times'+str(ID)+'_teffs.txt','w')\n",
    "\n",
    "    \n",
    "    for i,op in enumerate(OrdParam.values()):\n",
    "        resops =op.get_op_res\n",
    "        (op.avg, op.std, op.stem) =op.get_avg_std_stem_OP\n",
    "        \n",
    "        outfile_ind=open(str(dir_wrk)+'/tmp/'+str(ID)+'/'+op.name+'times_perlipid.txt','w')\n",
    "        convs=[]\n",
    "        Teffs=[]\n",
    "        Teffs_area=[]\n",
    "        R1s=[]\n",
    "        \n",
    "        for j in range(firstlipid,lastlipid+1):\n",
    "            print (op.name, j)\n",
    "            corrfile=dir_wrk+'/tmp/'+str(ID)+'/'+str(j)+'_rotacf_'+op.name+\".xvg\"\n",
    "            if j==1:\n",
    "                out,times=read_data(corrfile)\n",
    "                fvals=np.asmatrix(out).T\n",
    "            else:\n",
    "                out, times=read_data(corrfile)\n",
    "                fvals=np.concatenate((fvals,np.asmatrix(out).T),axis=1)\n",
    "            #Hanne: change to calc only R1 here\n",
    "            Teff,tau_eff_area, R1, conv =calc_corrtime_noread(out,times, resops[j-1])\n",
    "            Teffs.append(Teff)\n",
    "            Teffs_area.append(tau_eff_area)\n",
    "            R1s.append(R1)\n",
    "            convs.append(conv)\n",
    "            \n",
    "            line=str(op.name)+\" \"+str(resops[j-1])+\" \"+str(Teff)+\" \"+str(tau_eff_area)+\" \"+str(R1)+\" \"+str(conv)+ '\\n'\n",
    "            outfile_ind.write(line)\n",
    "        outfile_ind.close()\n",
    "\n",
    "        line2=str(op.name)+\" \"+str(op.avg)+\" \"+str(op.stem)+\" \"+str(np.mean(Teffs))+\" \"+str(np.std(Teffs, ddof=1)/np.sqrt(len(Teffs)-1))+\" \"+str(np.mean(Teffs_area))+\" \"+str(np.std(Teffs_area,ddof=1)/np.sqrt(len(Teffs_area)-1))+\" \"+str(np.mean(R1s))+\" \"+str(np.std(R1s, ddof=1)/np.sqrt(len(R1s)-1))+\" \"+str(sum(convs)/float(len(convs)))+'\\n'\n",
    "        outfile.write(line2)\n",
    "\n",
    "        #analysis of Teff error starts here\n",
    "        means=np.mean(fvals,axis=1)\n",
    "        stems=np.std(fvals,axis=1,ddof=1)/np.sqrt(int(numlipid)-1)\n",
    "        teff,teff_min,teff_max=calc_corrtime_withee(times,means, stems, op.avg, op.stem)\n",
    "        line3=str(op.name)+\" \"+str(op.avg)+\" \"+str(teff)+\" \"+str(teff_min)+\" \"+str(teff_max)+'\\n'\n",
    "        outfile_teffs.write(line3)        \n",
    "        line=str(op.name)+\" \"+str(op.avg)+\" \"+str(Teff)+\" \"+str(tau_eff_area)+\" \"+str(R1)+'\\n'\n",
    "\n",
    "    !cp {str(dir_wrk)}'/tmp/'{str(ID)}'/times'{str(ID)}'.txt' {DATAdir}\n",
    "    outfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
